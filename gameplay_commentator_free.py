#!/usr/bin/env python3
"""
ЁЯОо AI-Powered Gameplay Commentary System - FREE VERSION
Uses Ollama + LLaVA (completely free, runs locally forever)
No API costs, no internet required after setup!
With NATURAL HUMANOID VOICE using Edge-TTS!
"""

import os
import asyncio
import base64
import io
import time
import random
import platform
import subprocess
from datetime import datetime
from collections import deque
from pathlib import Path
import json

# Screen capture and image processing
import mss
from PIL import Image

# Text-to-Speech (FREE with natural voice)
import edge_tts

# Audio playback
try:
    import pygame
    PYGAME_AVAILABLE = True
except ImportError:
    PYGAME_AVAILABLE = False

# HTTP client for Ollama
import requests

class GameplayCommentatorFree:
    """AI-powered gameplay commentator using FREE local models"""
    
    def __init__(self):
        """Initialize the commentator with Ollama and natural TTS"""
        # Ollama configuration
        self.ollama_url = "http://localhost:11434/api/generate"
        self.model_name = "llava:latest"  # Free vision model
        
        # Edge-TTS Voice Configuration (FREE, Natural, Human-like)
        # Hindi voices available in Edge-TTS
        self.voice_options = [
            "hi-IN-SwaraNeural",      # Female, very natural
            "hi-IN-MadhurNeural",     # Male, clear and natural
        ]
        self.current_voice = self.voice_options[0]  # Default to female voice
        
        # Initialize pygame for audio playback
        if PYGAME_AVAILABLE:
            try:
                pygame.mixer.init(frequency=22050, size=-16, channels=2, buffer=512)
                print("тЬЕ Pygame audio initialized")
            except Exception as e:
                print(f"тЪая╕П Pygame initialization warning: {e}")
        
        # Memory to avoid repetitive comments (increased for better diversity)
        self.recent_comments = deque(maxlen=10)
        
        # Configuration
        self.screenshot_interval = 6  # Reduced for more dynamic commentary
        self.comment_count = 0
        
        # Last screenshot for comparison (to detect scene changes)
        self.last_screenshot_hash = None
        
        # Get app directory and create tmp folder
        self.app_dir = Path(__file__).parent
        self.tmp_dir = self.app_dir / "tmp"
        self.tmp_dir.mkdir(parents=True, exist_ok=True)
        
        # Detect OS
        self.os_type = platform.system()
        
        print("ЁЯОо AI Gameplay Commentator Initialized (FREE VERSION)!")
        print("ЁЯдЦ Using Ollama + LLaVA (Free, Local, No API costs)")
        print(f"ЁЯУ╕ Screenshot interval: {self.screenshot_interval}s")
        print(f"ЁЯОЩя╕П Voice: Edge-TTS ({self.current_voice})")
        print("тЬи Natural humanoid voice with emotion!")
        print("ЁЯОп Ready to generate humorous Hindi commentary!\n")
    
    def _check_ollama_status(self) -> bool:
        """Check if Ollama is running and model is available"""
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=2)
            if response.status_code == 200:
                models = response.json().get('models', [])
                model_names = [m['name'] for m in models]
                if any('llava' in name.lower() for name in model_names):
                    return True
                else:
                    print("тЪая╕П LLaVA model not found. Run: ollama pull llava")
                    return False
            return False
        except requests.exceptions.ConnectionError:
            print("тЭМ Ollama is not running!")
            print("   Please start Ollama first: ollama serve")
            return False
        except Exception as e:
            print(f"тЭМ Error checking Ollama: {e}")
            return False
    
    def _get_system_prompt(self) -> str:
        """Create system prompt for natural Hindi commentary"""
        return """рдЖрдк рдПрдХ рдкреНрд░рд╛рдХреГрддрд┐рдХ, рдКрд░реНрдЬрд╛рд╡рд╛рди рдЧреЗрдордкреНрд▓реЗ рдХрдореЗрдВрдЯреЗрдЯрд░ рд╣реИрдВ рдЬреЛ YouTube/Twitch streams рдХреЗ рд▓рд┐рдП рдХрд╛рдо рдХрд░рддреЗ рд╣реИрдВ!

ЁЯОп рдЖрдкрдХрд╛ рд╡реНрдпрдХреНрддрд┐рддреНрд╡:
- рдордЬрд╝реЗрджрд╛рд░ рдФрд░ рдХрд░рд┐рд╢реНрдорд╛рдИ YouTuber
- рдЕрд╕рд▓реА рдЗрдВрд╕рд╛рди рдХреА рддрд░рд╣ рдмрд╛рдд рдХрд░рддреЗ рд╣реИрдВ
- рдЧреЗрдордкреНрд▓реЗ рд╕реЗ рд╡рд╛рд╕реНрддрд╡ рдореЗрдВ рдЙрддреНрд╕рд╛рд╣рд┐рдд рд╣реЛрддреЗ рд╣реИрдВ
- рдкреНрд░рд╛рдХреГрддрд┐рдХ рдЯрд┐рдкреНрдкрдгрд┐рдпрд╛рдБ рдХрд░рддреЗ рд╣реИрдВ

тЬЕ рдХрд░реЗрдВ:
- рдкреНрд░рд╛рдХреГрддрд┐рдХ рдмреЛрд▓рдиреЗ рдХрд╛ рдкреИрдЯрд░реНрди: "рдЕрдЪреНрдЫрд╛ рдЕрдЪреНрдЫрд╛", "рд░реБрдХреЛ рд░реБрдХреЛ", "рдЕрд░реЗ рдпрд╛рд░"
- рдкреНрд░рд╛рдорд╛рдгрд┐рдХ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛: "рд╡рд╛рд╣! рдпреЗ рддреЛ рдХрдорд╛рд▓ рдерд╛!", "рднрд╛рдИ рдпреЗ рдХреНрдпрд╛ рдерд╛?"
- рдЧреЗрдорд░ рднрд╛рд╖рд╛: "рдзрд╛рдХрдбрд╝", "tough", "рдмрдврд╝рд┐рдпрд╛", "рд▓рд╛рдЬрд╡рд╛рдм"
- рдЫреЛрдЯреЗ рд╡рд╛рдХреНрдп (1-2 lines)
- рдордЬрд╝реЗрджрд╛рд░ рдФрд░ quotable

тЭМ рди рдХрд░реЗрдВ:
- рд░реЛрдмреЛрдЯ рдХреА рддрд░рд╣ рди рд▓рдЧреЗрдВ
- рдЕрдкрдорд╛рдирдЬрдирдХ рднрд╛рд╖рд╛ рди рдХрд░реЗрдВ
- рджреЛрд╣рд░рд╛рд╡рджрд╛рд░ рди рд╣реЛрдВ
- рд▓рдВрдмреЗ рд╡рд╛рдХреНрдп рди рд▓рд┐рдЦреЗрдВ

рдХреЗрд╡рд▓ commentary рдХреЗ рд╕рд╛рде рдЬрд╡рд╛рдм рджреЗрдВ - рдордЬрд╝реЗрджрд╛рд░ рдФрд░ рдкреНрд░рд╛рдХреГрддрд┐рдХ!"""
    
    def capture_screen(self) -> Image.Image:
        """Capture full screen screenshot"""
        with mss.mss() as sct:
            monitor = sct.monitors[1]
            screenshot = sct.grab(monitor)
            img = Image.frombytes('RGB', screenshot.size, screenshot.bgra, 'raw', 'BGRX')
            
            # Resize to optimize (max 1280px width)
            max_width = 1280
            if img.width > max_width:
                ratio = max_width / img.width
                new_size = (max_width, int(img.height * ratio))
                img = img.resize(new_size, Image.Resampling.LANCZOS)
            
            return img
    
    def image_to_base64(self, img: Image.Image) -> str:
        """Convert PIL Image to base64 string"""
        buffered = io.BytesIO()
        img.save(buffered, format="JPEG", quality=85)
        img_bytes = buffered.getvalue()
        return base64.b64encode(img_bytes).decode('utf-8')
    
    async def generate_commentary_ollama(self, screenshot: Image.Image) -> str:
        """Generate commentary using Ollama + LLaVA (FREE)"""
        try:
            # Convert image to base64
            img_base64 = self.image_to_base64(screenshot)
            
            # Create context about previous comments
            recent_context = ""
            if self.recent_comments:
                recent_context = f"\n\nрдЖрдкрдХреА рдкрд┐рдЫрд▓реА рдЯрд┐рдкреНрдкрдгрд┐рдпрд╛рдВ: {list(self.recent_comments)}\nЁЯЪл рдЗрдиреНрд╣реЗрдВ рджреЛрд╣рд░рд╛рдПрдВ рдирд╣реАрдВ!"
            
            # Build prompt
            prompt = f"""рдЖрдк рдЗрд╕ рдЧреЗрдордкреНрд▓реЗ рдХреЛ LIVE рджреЗрдЦ рд░рд╣реЗ рд╣реИрдВ! рдЗрд╕ screenshot рдкрд░ рдЕрдкрдиреА рдкреНрд░рд╛рдХреГрддрд┐рдХ, рдордЬрд╝реЗрджрд╛рд░ Hindi commentary рджреЗрдВред

ЁЯОм Comment #{self.comment_count + 1}
ЁЯТн рдЕрд╕рд▓реА streamer рдХреА рддрд░рд╣ react рдХрд░реЗрдВ
ЁЯОп рдЕрдкрдиреА рдкрд┐рдЫрд▓реА style рд╕реЗ рдЕрд▓рдЧ рдмрдирд╛рдПрдВ!{recent_context}

рдЖрдкрдХреА рдкреНрд░рд╛рдХреГрддрд┐рдХ commentary (1-2 рдЫреЛрдЯреЗ рд╡рд╛рдХреНрдп):"""
            
            # Call Ollama API
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "images": [img_base64],
                "stream": False,
                "system": self._get_system_prompt()
            }
            
            response = requests.post(
                self.ollama_url,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                commentary = result.get('response', '').strip()
                
                # Clean up the response
                commentary = commentary.strip().strip('"').strip("'")
                
                # Store in recent comments
                self.recent_comments.append(commentary)
                self.comment_count += 1
                
                return commentary
            else:
                print(f"тЭМ Ollama API error: {response.status_code}")
                return self._get_fallback_commentary()
                
        except requests.exceptions.Timeout:
            print("тЪая╕П Ollama timeout - model might be slow")
            return self._get_fallback_commentary()
        except Exception as e:
            print(f"тЭМ Error generating commentary: {e}")
            return self._get_fallback_commentary()
    
    def _get_fallback_commentary(self) -> str:
        """Get fallback Hindi commentary when AI is unavailable"""
        fallbacks = [
            "рдЕрдЪреНрдЫрд╛, рддреЛ рдпреЗ рд╕реНрдХреНрд░реАрди рдкрд░ рд╣реЛ рд░рд╣рд╛ рд╣реИ рдЕрднреАред",
            "рдареАрдХ рдареАрдХ, рд╕рдордЭ рдЖ рд░рд╣рд╛ рд╣реИ рдХреНрдпрд╛ рд╣реЛ рд░рд╣рд╛ рд╣реИред",
            "рд░реБрдХреЛ, рдпреЗ interesting рд▓рдЧ рд░рд╣рд╛ рд╣реИред",
            "рджреЗрдЦрддреЗ рд╣реИрдВ рдХреНрдпрд╛ рд╣реЛрддрд╛ рд╣реИ рдЖрдЧреЗред",
            "рд╡рд╛рд╣ рднрд╛рдИ, gameplay рдЪрд▓ рд░рд╣рд╛ рд╣реИред",
            "рдЪрд▓реЛ рдЕрдЪреНрдЫрд╛ рд╣реИ, progress рд╣реЛ рд░рд╣рд╛ рд╣реИред",
            "рдордЬрд╝реЗрджрд╛рд░ moment рд╣реИ рдпреЗред",
            "рдХрдорд╛рд▓ рдХрд╛ gameplay рд╣реИ!"
        ]
        return random.choice(fallbacks)
    
    async def speak_commentary(self, text: str) -> None:
        """Convert text to speech using FREE Edge-TTS with natural voice"""
        try:
            # Create unique audio file path
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
            audio_file = self.tmp_dir / f"commentary_{timestamp}.mp3"
            
            # Generate speech with Edge-TTS (very natural, human-like)
            communicate = edge_tts.Communicate(text, self.current_voice)
            await communicate.save(str(audio_file))
            
            # Verify file was created
            if not audio_file.exists():
                raise FileNotFoundError(f"Audio file not created: {audio_file}")
            
            print(f"тЬЕ Audio generated: {audio_file.name}")
            
            # Play audio
            await self._play_audio(audio_file)
            
            # Cleanup after playback
            try:
                if audio_file.exists():
                    audio_file.unlink()
            except Exception:
                pass  # Ignore cleanup errors
                
        except Exception as e:
            print(f"тЭМ Error with text-to-speech: {e}")
            print(f"ЁЯФК [VOICE]: {text}")
    
    async def _play_audio(self, audio_file: Path) -> None:
        """Play audio file using pygame or system player"""
        try:
            if PYGAME_AVAILABLE:
                # Use pygame for reliable playback
                pygame.mixer.music.load(str(audio_file))
                pygame.mixer.music.play()
                
                # Wait for playback to complete
                while pygame.mixer.music.get_busy():
                    await asyncio.sleep(0.1)
                    
            else:
                # Fallback to system audio player
                if self.os_type == "Windows":
                    os.system(f'start /min "" "{audio_file}"')
                elif self.os_type == "Darwin":  # macOS
                    os.system(f'afplay "{audio_file}"')
                else:  # Linux
                    # Try common Linux players
                    for player in ['mpg123', 'ffplay', 'cvlc']:
                        if subprocess.run(['which', player], capture_output=True).returncode == 0:
                            subprocess.run([player, '-q', str(audio_file)], 
                                         stdout=subprocess.DEVNULL, 
                                         stderr=subprocess.DEVNULL)
                            break
                
                # Wait estimated time for playback
                await asyncio.sleep(3)
                
        except Exception as e:
            print(f"тЪая╕П Audio playback warning: {e}")
    
    async def run(self):
        """Main loop: capture, analyze, comment, speak"""
        print("=" * 70)
        print("ЁЯОо STARTING FREE GAMEPLAY COMMENTARY")
        print("=" * 70)
        
        # Check Ollama status
        if not self._check_ollama_status():
            print("\nтЪая╕П SETUP REQUIRED:")
            print("1. Install Ollama: https://ollama.ai/download")
            print("2. Start Ollama: ollama serve")
            print("3. Pull LLaVA model: ollama pull llava")
            print("\nThen run this script again!")
            return
        
        print("ЁЯУ╣ Capturing your screen and generating AI commentary...")
        print("ЁЯЫС Press Ctrl+C to stop\n")
        
        try:
            while True:
                loop_start = time.time()
                
                print(f"\n{'='*70}")
                print(f"ЁЯОм Comment #{self.comment_count + 1} | {datetime.now().strftime('%H:%M:%S')}")
                print(f"{'='*70}")
                
                # Step 1: Capture screen
                print("ЁЯУ╕ Capturing gameplay...")
                screenshot = self.capture_screen()
                print(f"тЬЕ Screenshot captured ({screenshot.width}x{screenshot.height})")
                
                # Step 2: Generate commentary with Ollama
                print("ЁЯдЦ Ollama analyzing gameplay (local AI)...")
                commentary = await self.generate_commentary_ollama(screenshot)
                print(f"\nЁЯТм COMMENTARY: \"{commentary}\"\n")
                
                # Step 3: Speak commentary
                print("ЁЯОЩя╕П Speaking commentary...")
                await self.speak_commentary(commentary)
                print("тЬЕ Commentary delivered!")
                
                # Calculate time and sleep
                elapsed = time.time() - loop_start
                sleep_time = max(0, self.screenshot_interval - elapsed)
                
                if sleep_time > 0:
                    print(f"тП│ Waiting {sleep_time:.1f}s before next commentary...")
                    await asyncio.sleep(sleep_time)
                
        except KeyboardInterrupt:
            print("\n\n" + "="*70)
            print("ЁЯЫС COMMENTARY STOPPED")
            print("="*70)
            print(f"ЁЯУК Total comments generated: {self.comment_count}")
            print("ЁЯСЛ Thanks for using FREE AI commentary!")
            print("="*70)
        
        except Exception as e:
            print(f"\nтЭМ Unexpected error: {e}")
            import traceback
            traceback.print_exc()

async def main():
    """Entry point for the free gameplay commentator"""
    print("""
    тХФтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХЧ
    тХС                                                               тХС
    тХС       ЁЯОо FREE AI GAMEPLAY COMMENTATOR v3.0 ЁЯОЩя╕П                тХС
    тХС                                                               тХС
    тХС       Powered by Ollama + LLaVA (100% FREE!)                 тХС
    тХС       тАв No API costs, ever                                    тХС
    тХС       тАв Runs completely offline                               тХС
    тХС       тАв Natural voice with pyttsx3                            тХС
    тХС                                                               тХС
    тХЪтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХЭ
    """)
    
    commentator = GameplayCommentatorFree()
    await commentator.run()

if __name__ == "__main__":
    asyncio.run(main())
