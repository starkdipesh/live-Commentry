#!/usr/bin/env python3
"""
ЁЯОо AI-Powered Gameplay Commentary System - FREE VERSION
Uses Ollama + LLaVA (completely free, runs locally forever)
No API costs, no internet required after setup!
"""

import os
import asyncio
import base64
import io
import time
import random
import platform
import subprocess
from datetime import datetime
from collections import deque
from pathlib import Path
import json

# Screen capture and image processing
import mss
from PIL import Image

# Text-to-Speech (FREE offline)
import pyttsx3

# HTTP client for Ollama
import requests

class GameplayCommentatorFree:
    """AI-powered gameplay commentator using FREE local models"""
    
    def __init__(self):
        """Initialize the commentator with Ollama and local TTS"""
        # Ollama configuration
        self.ollama_url = "http://localhost:11434/api/generate"
        self.model_name = "llava:latest"  # Free vision model
        
        # Initialize Text-to-Speech engine (offline, free)
        try:
            self.tts_engine = pyttsx3.init()
            # Configure voice settings for natural speech
            voices = self.tts_engine.getProperty('voices')
            
            # Try to find a Hindi voice, fallback to English
            hindi_voice = None
            for voice in voices:
                if 'hindi' in voice.name.lower() or 'hi' in voice.languages:
                    hindi_voice = voice.id
                    break
            
            if hindi_voice:
                self.tts_engine.setProperty('voice', hindi_voice)
            
            # Set natural speech rate (150-200 is natural)
            self.tts_engine.setProperty('rate', 165)
            # Set volume (0.0 to 1.0)
            self.tts_engine.setProperty('volume', 0.9)
            
            print("тЬЕ TTS Engine initialized (Free offline voice)")
        except Exception as e:
            print(f"тЪая╕П TTS initialization warning: {e}")
            self.tts_engine = None
        
        # Memory to avoid repetitive comments
        self.recent_comments = deque(maxlen=5)
        
        # Configuration
        self.screenshot_interval = 8
        self.comment_count = 0
        
        # Get app directory
        self.app_dir = Path(__file__).parent
        
        # Detect OS
        self.os_type = platform.system()
        
        print("ЁЯОо AI Gameplay Commentator Initialized (FREE VERSION)!")
        print("ЁЯдЦ Using Ollama + LLaVA (Free, Local, No API costs)")
        print(f"ЁЯУ╕ Screenshot interval: {self.screenshot_interval}s")
        print(f"ЁЯФК Voice: Offline TTS ({self.os_type})")
        print("ЁЯОЩя╕П Ready to generate humorous Hindi commentary!\n")
    
    def _check_ollama_status(self) -> bool:
        """Check if Ollama is running and model is available"""
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=2)
            if response.status_code == 200:
                models = response.json().get('models', [])
                model_names = [m['name'] for m in models]
                if any('llava' in name.lower() for name in model_names):
                    return True
                else:
                    print("тЪая╕П LLaVA model not found. Run: ollama pull llava")
                    return False
            return False
        except requests.exceptions.ConnectionError:
            print("тЭМ Ollama is not running!")
            print("   Please start Ollama first: ollama serve")
            return False
        except Exception as e:
            print(f"тЭМ Error checking Ollama: {e}")
            return False
    
    def _get_system_prompt(self) -> str:
        """Create system prompt for natural Hindi commentary"""
        return """рдЖрдк рдПрдХ рдкреНрд░рд╛рдХреГрддрд┐рдХ, рдКрд░реНрдЬрд╛рд╡рд╛рди рдЧреЗрдордкреНрд▓реЗ рдХрдореЗрдВрдЯреЗрдЯрд░ рд╣реИрдВ рдЬреЛ YouTube/Twitch streams рдХреЗ рд▓рд┐рдП рдХрд╛рдо рдХрд░рддреЗ рд╣реИрдВ!

ЁЯОп рдЖрдкрдХрд╛ рд╡реНрдпрдХреНрддрд┐рддреНрд╡:
- рдордЬрд╝реЗрджрд╛рд░ рдФрд░ рдХрд░рд┐рд╢реНрдорд╛рдИ YouTuber
- рдЕрд╕рд▓реА рдЗрдВрд╕рд╛рди рдХреА рддрд░рд╣ рдмрд╛рдд рдХрд░рддреЗ рд╣реИрдВ
- рдЧреЗрдордкреНрд▓реЗ рд╕реЗ рд╡рд╛рд╕реНрддрд╡ рдореЗрдВ рдЙрддреНрд╕рд╛рд╣рд┐рдд рд╣реЛрддреЗ рд╣реИрдВ
- рдкреНрд░рд╛рдХреГрддрд┐рдХ рдЯрд┐рдкреНрдкрдгрд┐рдпрд╛рдБ рдХрд░рддреЗ рд╣реИрдВ

тЬЕ рдХрд░реЗрдВ:
- рдкреНрд░рд╛рдХреГрддрд┐рдХ рдмреЛрд▓рдиреЗ рдХрд╛ рдкреИрдЯрд░реНрди: "рдЕрдЪреНрдЫрд╛ рдЕрдЪреНрдЫрд╛", "рд░реБрдХреЛ рд░реБрдХреЛ", "рдЕрд░реЗ рдпрд╛рд░"
- рдкреНрд░рд╛рдорд╛рдгрд┐рдХ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛: "рд╡рд╛рд╣! рдпреЗ рддреЛ рдХрдорд╛рд▓ рдерд╛!", "рднрд╛рдИ рдпреЗ рдХреНрдпрд╛ рдерд╛?"
- рдЧреЗрдорд░ рднрд╛рд╖рд╛: "рдзрд╛рдХрдбрд╝", "tough", "рдмрдврд╝рд┐рдпрд╛", "рд▓рд╛рдЬрд╡рд╛рдм"
- рдЫреЛрдЯреЗ рд╡рд╛рдХреНрдп (1-2 lines)
- рдордЬрд╝реЗрджрд╛рд░ рдФрд░ quotable

тЭМ рди рдХрд░реЗрдВ:
- рд░реЛрдмреЛрдЯ рдХреА рддрд░рд╣ рди рд▓рдЧреЗрдВ
- рдЕрдкрдорд╛рдирдЬрдирдХ рднрд╛рд╖рд╛ рди рдХрд░реЗрдВ
- рджреЛрд╣рд░рд╛рд╡рджрд╛рд░ рди рд╣реЛрдВ
- рд▓рдВрдмреЗ рд╡рд╛рдХреНрдп рди рд▓рд┐рдЦреЗрдВ

рдХреЗрд╡рд▓ commentary рдХреЗ рд╕рд╛рде рдЬрд╡рд╛рдм рджреЗрдВ - рдордЬрд╝реЗрджрд╛рд░ рдФрд░ рдкреНрд░рд╛рдХреГрддрд┐рдХ!"""
    
    def capture_screen(self) -> Image.Image:
        """Capture full screen screenshot"""
        with mss.mss() as sct:
            monitor = sct.monitors[1]
            screenshot = sct.grab(monitor)
            img = Image.frombytes('RGB', screenshot.size, screenshot.bgra, 'raw', 'BGRX')
            
            # Resize to optimize (max 1280px width)
            max_width = 1280
            if img.width > max_width:
                ratio = max_width / img.width
                new_size = (max_width, int(img.height * ratio))
                img = img.resize(new_size, Image.Resampling.LANCZOS)
            
            return img
    
    def image_to_base64(self, img: Image.Image) -> str:
        """Convert PIL Image to base64 string"""
        buffered = io.BytesIO()
        img.save(buffered, format="JPEG", quality=85)
        img_bytes = buffered.getvalue()
        return base64.b64encode(img_bytes).decode('utf-8')
    
    async def generate_commentary_ollama(self, screenshot: Image.Image) -> str:
        """Generate commentary using Ollama + LLaVA (FREE)"""
        try:
            # Convert image to base64
            img_base64 = self.image_to_base64(screenshot)
            
            # Create context about previous comments
            recent_context = ""
            if self.recent_comments:
                recent_context = f"\n\nрдЖрдкрдХреА рдкрд┐рдЫрд▓реА рдЯрд┐рдкреНрдкрдгрд┐рдпрд╛рдВ: {list(self.recent_comments)}\nЁЯЪл рдЗрдиреНрд╣реЗрдВ рджреЛрд╣рд░рд╛рдПрдВ рдирд╣реАрдВ!"
            
            # Build prompt
            prompt = f"""рдЖрдк рдЗрд╕ рдЧреЗрдордкреНрд▓реЗ рдХреЛ LIVE рджреЗрдЦ рд░рд╣реЗ рд╣реИрдВ! рдЗрд╕ screenshot рдкрд░ рдЕрдкрдиреА рдкреНрд░рд╛рдХреГрддрд┐рдХ, рдордЬрд╝реЗрджрд╛рд░ Hindi commentary рджреЗрдВред

ЁЯОм Comment #{self.comment_count + 1}
ЁЯТн рдЕрд╕рд▓реА streamer рдХреА рддрд░рд╣ react рдХрд░реЗрдВ
ЁЯОп рдЕрдкрдиреА рдкрд┐рдЫрд▓реА style рд╕реЗ рдЕрд▓рдЧ рдмрдирд╛рдПрдВ!{recent_context}

рдЖрдкрдХреА рдкреНрд░рд╛рдХреГрддрд┐рдХ commentary (1-2 рдЫреЛрдЯреЗ рд╡рд╛рдХреНрдп):"""
            
            # Call Ollama API
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "images": [img_base64],
                "stream": False,
                "system": self._get_system_prompt()
            }
            
            response = requests.post(
                self.ollama_url,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                commentary = result.get('response', '').strip()
                
                # Clean up the response
                commentary = commentary.strip().strip('"').strip("'")
                
                # Store in recent comments
                self.recent_comments.append(commentary)
                self.comment_count += 1
                
                return commentary
            else:
                print(f"тЭМ Ollama API error: {response.status_code}")
                return self._get_fallback_commentary()
                
        except requests.exceptions.Timeout:
            print("тЪая╕П Ollama timeout - model might be slow")
            return self._get_fallback_commentary()
        except Exception as e:
            print(f"тЭМ Error generating commentary: {e}")
            return self._get_fallback_commentary()
    
    def _get_fallback_commentary(self) -> str:
        """Get fallback Hindi commentary when AI is unavailable"""
        fallbacks = [
            "рдЕрдЪреНрдЫрд╛, рддреЛ рдпреЗ рд╕реНрдХреНрд░реАрди рдкрд░ рд╣реЛ рд░рд╣рд╛ рд╣реИ рдЕрднреАред",
            "рдареАрдХ рдареАрдХ, рд╕рдордЭ рдЖ рд░рд╣рд╛ рд╣реИ рдХреНрдпрд╛ рд╣реЛ рд░рд╣рд╛ рд╣реИред",
            "рд░реБрдХреЛ, рдпреЗ interesting рд▓рдЧ рд░рд╣рд╛ рд╣реИред",
            "рджреЗрдЦрддреЗ рд╣реИрдВ рдХреНрдпрд╛ рд╣реЛрддрд╛ рд╣реИ рдЖрдЧреЗред",
            "рд╡рд╛рд╣ рднрд╛рдИ, gameplay рдЪрд▓ рд░рд╣рд╛ рд╣реИред",
            "рдЪрд▓реЛ рдЕрдЪреНрдЫрд╛ рд╣реИ, progress рд╣реЛ рд░рд╣рд╛ рд╣реИред",
            "рдордЬрд╝реЗрджрд╛рд░ moment рд╣реИ рдпреЗред",
            "рдХрдорд╛рд▓ рдХрд╛ gameplay рд╣реИ!"
        ]
        return random.choice(fallbacks)
    
    def speak_commentary(self, text: str) -> None:
        """Convert text to speech using FREE offline TTS"""
        try:
            if self.tts_engine:
                # Use pyttsx3 for offline, natural voice
                self.tts_engine.say(text)
                self.tts_engine.runAndWait()
            else:
                # Fallback: just print if TTS not available
                print(f"ЁЯФК [VOICE]: {text}")
        except Exception as e:
            print(f"тЭМ Error with text-to-speech: {e}")
            print(f"ЁЯФК [VOICE]: {text}")
    
    async def run(self):
        """Main loop: capture, analyze, comment, speak"""
        print("=" * 70)
        print("ЁЯОо STARTING FREE GAMEPLAY COMMENTARY")
        print("=" * 70)
        
        # Check Ollama status
        if not self._check_ollama_status():
            print("\nтЪая╕П SETUP REQUIRED:")
            print("1. Install Ollama: https://ollama.ai/download")
            print("2. Start Ollama: ollama serve")
            print("3. Pull LLaVA model: ollama pull llava")
            print("\nThen run this script again!")
            return
        
        print("ЁЯУ╣ Capturing your screen and generating AI commentary...")
        print("ЁЯЫС Press Ctrl+C to stop\n")
        
        try:
            while True:
                loop_start = time.time()
                
                print(f"\n{'='*70}")
                print(f"ЁЯОм Comment #{self.comment_count + 1} | {datetime.now().strftime('%H:%M:%S')}")
                print(f"{'='*70}")
                
                # Step 1: Capture screen
                print("ЁЯУ╕ Capturing gameplay...")
                screenshot = self.capture_screen()
                print(f"тЬЕ Screenshot captured ({screenshot.width}x{screenshot.height})")
                
                # Step 2: Generate commentary with Ollama
                print("ЁЯдЦ Ollama analyzing gameplay (local AI)...")
                commentary = await self.generate_commentary_ollama(screenshot)
                print(f"\nЁЯТм COMMENTARY: \"{commentary}\"\n")
                
                # Step 3: Speak commentary
                print("ЁЯОЩя╕П Speaking commentary...")
                self.speak_commentary(commentary)
                print("тЬЕ Commentary delivered!")
                
                # Calculate time and sleep
                elapsed = time.time() - loop_start
                sleep_time = max(0, self.screenshot_interval - elapsed)
                
                if sleep_time > 0:
                    print(f"тП│ Waiting {sleep_time:.1f}s before next commentary...")
                    await asyncio.sleep(sleep_time)
                
        except KeyboardInterrupt:
            print("\n\n" + "="*70)
            print("ЁЯЫС COMMENTARY STOPPED")
            print("="*70)
            print(f"ЁЯУК Total comments generated: {self.comment_count}")
            print("ЁЯСЛ Thanks for using FREE AI commentary!")
            print("="*70)
        
        except Exception as e:
            print(f"\nтЭМ Unexpected error: {e}")
            import traceback
            traceback.print_exc()

async def main():
    """Entry point for the free gameplay commentator"""
    print("""
    тХФтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХЧ
    тХС                                                               тХС
    тХС       ЁЯОо FREE AI GAMEPLAY COMMENTATOR v3.0 ЁЯОЩя╕П                тХС
    тХС                                                               тХС
    тХС       Powered by Ollama + LLaVA (100% FREE!)                 тХС
    тХС       тАв No API costs, ever                                    тХС
    тХС       тАв Runs completely offline                               тХС
    тХС       тАв Natural voice with pyttsx3                            тХС
    тХС                                                               тХС
    тХЪтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХЭ
    """)
    
    commentator = GameplayCommentatorFree()
    await commentator.run()

if __name__ == "__main__":
    asyncio.run(main())
