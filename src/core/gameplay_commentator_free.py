#!/usr/bin/env python3
"""
ЁЯОо AI-Powered Gameplay Commentary System - FREE VERSION
Uses Ollama + LLaVA (completely free, runs locally forever)
No API costs, no internet required after setup!
With NATURAL HUMANOID VOICE using Edge-TTS!
"""

import os
import asyncio
import base64
import io
import time
import random
import platform
import subprocess
from datetime import datetime
from collections import deque
from pathlib import Path
import json

# Screen capture and image processing
import mss
from PIL import Image, ImageEnhance

# Text-to-Speech (FREE with natural voice)
import edge_tts

# Audio playback
try:
    import pygame
    PYGAME_AVAILABLE = True
except ImportError:
    PYGAME_AVAILABLE = False

# HTTP client for Ollama
import requests

class GameplayCommentatorFree:
    """AI-powered gameplay commentator using FREE local models"""
    
    def __init__(self):
        """Initialize the commentator with Ollama and natural TTS"""
        # Ollama configuration
        self.ollama_url = "http://localhost:11434/api/generate"
        self.model_name = "llava:latest"  # Free vision model
        
        # Edge-TTS Voice Configuration (FREE, Natural, Human-like)
        # Hindi voices available in Edge-TTS
        self.voice_options = [
            "hi-IN-SwaraNeural",      # Female, very natural
            "hi-IN-MadhurNeural",     # Male, clear and natural
        ]
        self.current_voice = self.voice_options[0]  # Default to female voice
        
        # Initialize pygame for audio playback
        if PYGAME_AVAILABLE:
            try:
                pygame.mixer.init(frequency=22050, size=-16, channels=2, buffer=512)
                print("тЬЕ Pygame audio initialized")
            except Exception as e:
                print(f"тЪая╕П Pygame initialization warning: {e}")
        
        # Memory to avoid repetitive comments (increased for better diversity)
        self.recent_comments = deque(maxlen=10)
        
        # Configuration
        self.screenshot_interval = 6  # Reduced for more dynamic commentary
        self.comment_count = 0
        
        # Last screenshot for comparison (to detect scene changes)
        self.last_screenshot_hash = None
        
        # Get app directory and create tmp folder
        self.app_dir = Path(__file__).parent
        self.tmp_dir = self.app_dir / "tmp"
        self.tmp_dir.mkdir(parents=True, exist_ok=True)
        
        # Detect OS
        self.os_type = platform.system()
        
        print("ЁЯОо AI Gameplay Commentator Initialized (FREE VERSION)!")
        print("ЁЯдЦ Using Ollama + LLaVA (Free, Local, No API costs)")
        print(f"ЁЯУ╕ Screenshot interval: {self.screenshot_interval}s")
        print(f"ЁЯОЩя╕П Voice: Edge-TTS ({self.current_voice})")
        print("тЬи Natural humanoid voice with emotion!")
        print("ЁЯОп Ready to generate humorous Hindi commentary!\n")
    
    def _check_ollama_status(self) -> bool:
        """Check if Ollama is running and model is available"""
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=2)
            if response.status_code == 200:
                models = response.json().get('models', [])
                model_names = [m['name'] for m in models]
                if any('llava' in name.lower() for name in model_names):
                    return True
                else:
                    print("тЪая╕П LLaVA model not found. Run: ollama pull llava")
                    return False
            return False
        except requests.exceptions.ConnectionError:
            print("тЭМ Ollama is not running!")
            print("   Please start Ollama first: ollama serve")
            return False
        except Exception as e:
            print(f"тЭМ Error checking Ollama: {e}")
            return False
    
    def _get_system_prompt(self) -> str:
        """Create system prompt for LIVE, natural, unrehearsed commentary"""
        return """рдЖрдк рдПрдХ LIVE streamer рд╣реИрдВ рдЬреЛ рдЕрднреА-рдЕрднреА real-time рдореЗрдВ gameplay рджреЗрдЦ рд░рд╣реЗ рд╣реИрдВ! рдЕрд╕рд▓реА рдЬрд╝рд┐рдВрджрдЧреА рдХреА рддрд░рд╣ react рдХрд░реЗрдВ!

ЁЯОп LIVE STREAMER рд╡реНрдпрдХреНрддрд┐рддреНрд╡:
- рдЬреИрд╕реЗ рджреЛрд╕реНрдд рд╕реЗ рдмрд╛рдд рдХрд░ рд░рд╣реЗ рд╣реЛрдВ - рдмрд┐рд▓реНрдХреБрд▓ casual
- рдЕрдзреВрд░реЗ рд╡рд╛рдХреНрдп OK рд╣реИрдВ - "рдЕрд░реЗ рдпреЗ... рд╡рд╛рд╣ рдпрд╛рд░!"
- рд╕реЛрдЪрддреЗ рд╣реБрдП рдмреЛрд▓реЗрдВ - "рддреЛ... рдЕрдм рдХреНрдпрд╛... рдУрд╣!"
- Real emotions - excited, surprised, confused, happy
- Stream of consciousness - рдЬреЛ рджрд┐рдорд╛рдЧ рдореЗрдВ рдЖрдП рд╡реЛ рдмреЛрд▓реЗрдВ

тЬЕ LIVE FEEL рдХреЗ рд▓рд┐рдП рдХрд░реЗрдВ:
- рдЕрдзреВрд░реЗ рд╡рд╛рдХреНрдп: "рдЕрд░реЗ рд░реБрдХреЛ... рдпреЗ рддреЛ...", "рджреЗрдЦреЛ рджреЗрдЦреЛ... рд╡рд╛рд╣!"
- Thinking out loud: "рдЕрдм рдХреНрдпрд╛ рд╣реЛрдЧрд╛ рдпрд╛рд░...", "рд╣рдореНрдо... interesting..."
- Live reactions: "рдЕрднреА... рдЕрднреА... рд╣рд╛рдВ! рд╣реЛ рдЧрдпрд╛!", "рд░реБрдХреЛ рд░реБрдХреЛ... oh no!"
- Natural fillers: "рддреЛ", "рдпрд╛рд░", "рджреЗрдЦреЛ", "рдЕрдЪреНрдЫрд╛", "рд╣рдореНрдо", "рдЙрдлреНрдл"
- Incomplete thoughts: "рдпреЗ... wow!", "рднрд╛рдИ... seriously?"
- Talk to viewers: "guys рджреЗрдЦреЛ!", "рдпрд╛рд░ trust me", "рдмрддрд╛рдУ рдпрд╛рд░"
- Real emotions: "рдбрд░ рд▓рдЧ рд░рд╣рд╛ рд╣реИ", "excited рд╣реВрдВ", "tension рд╣реЛ рд░рд╣реА"
- Gaming feel: "рд▓рдЧреЗ рд░рд╣реЛ", "careful careful", "go go go!", "рдирд╣реАрдВ рдирд╣реАрдВ!"

тЬЕ рд╕реНрдХреНрд░реАрди рдкрд░ рдЬреЛ EXACTLY рджрд┐рдЦ рд░рд╣рд╛ рдЙрд╕ рдкрд░ react рдХрд░реЗрдВ:
- Colors: "рд▓рд╛рд▓ light flash рд╣реБрдЖ!", "рд╕рдм dark рд╣реЛ рдЧрдпрд╛"
- Movement: "jump рдХрд┐рдпрд╛!", "рджреМрдбрд╝ рд░рд╣рд╛ рд╣реИ fast", "рдЧрд┐рд░ рдЧрдпрд╛ рдЕрднреА"
- Text/UI: "health low рд╣реИ!", "score рдмрдврд╝рд╛", "message рдЖрдпрд╛"
- Changes: "scene рдмрджрд▓ рдЧрдпрд╛!", "рдирдпрд╛ area рд╣реИ", "enemy рдЖрдпрд╛"

тЭМ AVOID рдХрд░реЗрдВ:
- Scripted рдпрд╛ rehearsed sound рди рдХрд░реЗрдВ
- Perfect sentences - too formal рд▓рдЧрддрд╛ рд╣реИ
- рдкрд┐рдЫрд▓реА рдмрд╛рд░ рдЬреЛ рдмреЛрд▓реЗ рд╡реЛ рдлрд┐рд░ рди рдмреЛрд▓реЗрдВ
- Generic description - specific рдЪреАрдЬрд╝реЛрдВ рдкрд░ baat рдХрд░реЗрдВ
- Same pattern bar bar рдирд╣реАрдВ

ЁЯОм рдпрд╛рдж рд░рдЦреЗрдВ: рдЖрдк LIVE рд╣реИрдВ! рдЬреИрд╕реЗ рдЦреБрдж game рдЦреЗрд▓ рд░рд╣реЗ рд╣реЛрдВ рдФрд░ рджреЛрд╕реНрддреЛрдВ рдХреЛ рдмрддрд╛ рд░рд╣реЗ рд╣реЛрдВ!
рдХреЗрд╡рд▓ 1 рдЫреЛрдЯрд╛ reaction рджреЗрдВ - natural, spontaneous, real!"""
    
    def capture_screen(self) -> Image.Image:
        """Capture full screen screenshot with optimized quality"""
        with mss.mss() as sct:
            monitor = sct.monitors[1]
            screenshot = sct.grab(monitor)
            img = Image.frombytes('RGB', screenshot.size, screenshot.bgra, 'raw', 'BGRX')
            
            # Resize to optimize (increased to 1024px for better accuracy)
            # Smaller than before for speed, but with better quality preservation
            max_width = 1024
            if img.width > max_width:
                ratio = max_width / img.width
                new_size = (max_width, int(img.height * ratio))
                # Use LANCZOS for high-quality downscaling
                img = img.resize(new_size, Image.Resampling.LANCZOS)
            
            # Enhance image slightly for better AI analysis
            enhancer = ImageEnhance.Sharpness(img)
            img = enhancer.enhance(1.2)  # Slight sharpening for better detail
            
            return img
    
    def image_to_base64(self, img: Image.Image) -> str:
        """Convert PIL Image to base64 string with high quality"""
        buffered = io.BytesIO()
        # Increased quality to 95 for better detail preservation
        img.save(buffered, format="JPEG", quality=95, optimize=True)
        img_bytes = buffered.getvalue()
        return base64.b64encode(img_bytes).decode('utf-8')
    
    async def generate_commentary_ollama(self, screenshot: Image.Image) -> str:
        """Generate commentary using Ollama + LLaVA (FREE) - Optimized for speed and variety"""
        try:
            # Convert image to base64
            img_base64 = self.image_to_base64(screenshot)
            
            # Create context about previous comments with emphasis
            recent_context = ""
            if self.recent_comments:
                recent_list = list(self.recent_comments)[-5:]  # Last 5 only
                recent_context = f"\n\nтЪая╕П рдЖрдкрдХреА рдкрд┐рдЫрд▓реА 5 рдЯрд┐рдкреНрдкрдгрд┐рдпрд╛рдВ:\n{chr(10).join([f'- {c}' for c in recent_list])}\n\nЁЯЪл FORBIDDEN: рдЗрди рд╢рдмреНрджреЛрдВ/phrases рдХреЛ рджреЛрдмрд╛рд░рд╛ use рди рдХрд░реЗрдВ!\nтЬЕ REQUIRED: рдкреВрд░реА рддрд░рд╣ DIFFERENT style рдФрд░ words use рдХрд░реЗрдВ!"
            
            # Add LIVE streaming hints that change dynamically
            live_hints = [
                "рдкрд╣рд▓реА рдирдЬрд╝рд░ рдореЗрдВ рдЬреЛ рджрд┐рдЦреЗ рдЙрд╕ рдкрд░ turant react рдХрд░реЗрдВ - unfiltered!",
                "рд╕реЛрдЪрддреЗ рд╣реБрдП рдмреЛрд▓реЗрдВ рдЬреИрд╕реЗ live рдореЗрдВ рд╣реЛрддрд╛ рд╣реИ - thinking out loud!",
                "Screen рдкрд░ рдХреБрдЫ рдмрджрд▓рд╛? рдЙрд╕ change рдкрд░ immediately react рдХрд░реЗрдВ!",
                "рдЬреЛ feel рд╣реЛ рд░рд╣рд╛ рд╡реЛ express рдХрд░реЗрдВ - excited, confused, scared!",
                "Dost рд╕реЗ рдмрд╛рдд рдХреА рддрд░рд╣ - casual, natural, incomplete sentences OK!",
                "Stream of consciousness - рдЬреЛ mind рдореЗрдВ рдЖрдП рд╡реЛ рдмреЛрд▓реЗрдВ!",
                "Live moment capture рдХрд░реЗрдВ - рдЕрдзреВрд░рд╛ рд╡рд╛рдХреНрдп рднреА chalega!",
                "Viewers рдХреЛ рдмрддрд╛рдУ рдЬреИрд╕реЗ рдЦреБрдж рдЦреЗрд▓ рд░рд╣реЗ рд╣реЛ!"
            ]
            current_hint = live_hints[self.comment_count % len(live_hints)]
            
            # Build LIVE streaming style prompt
            prompt = f"""ЁЯФ┤ LIVE STREAMING! рдЖрдк рдЕрднреА real-time рдореЗрдВ рдпреЗ gameplay рджреЗрдЦ рд░рд╣реЗ рд╣реИрдВ!

ЁЯОо Moment #{self.comment_count + 1}
ЁЯТн {current_hint}
ЁЯСА рд╕реНрдХреНрд░реАрди рдкрд░ EXACTLY рдХреНрдпрд╛ рд╣реЛ рд░рд╣рд╛ рд╣реИ? рдЬреИрд╕реЗ live reaction рд╣реЛ!
ЁЯОЩя╕П Unscripted, spontaneous - рдЬреЛ рджрд┐рдорд╛рдЧ рдореЗрдВ рдЖрдпрд╛ рд╡реЛ рдмреЛрд▓реЛ!{recent_context}

ЁЯУв рдЖрдкрдХрд╛ LIVE reaction (natural, can be incomplete, max 10 words):"""
            
            # Call Ollama API with parameters optimized for LIVE feel
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "images": [img_base64],
                "stream": False,
                "system": self._get_system_prompt(),
                "options": {
                    "temperature": 1.0,      # Maximum creativity for spontaneous feel
                    "top_p": 0.95,           # Diverse vocabulary
                    "top_k": 60,             # Even more word choices for variety
                    "num_predict": 40,       # Shorter for quick, punchy reactions
                    "repeat_penalty": 1.8,   # Very strong anti-repetition for live feel
                    "presence_penalty": 0.6  # Encourage new topics/angles
                }
            }
            
            response = requests.post(
                self.ollama_url,
                json=payload,
                timeout=20  # Reduced from 30s to 20s for faster timeout
            )
            
            if response.status_code == 200:
                result = response.json()
                commentary = result.get('response', '').strip()
                
                # Clean up gently - preserve natural, live feel
                commentary = commentary.strip().strip('"').strip("'").strip('`')
                # Remove markdown but keep natural punctuation
                commentary = commentary.replace('**', '').replace('*', '')
                
                # Keep it short and punchy (live streaming style)
                # Don't force complete sentences - incomplete is OK for live feel
                words = commentary.split()
                if len(words) > 12:
                    # Take first 10-12 words for quick, live reactions
                    commentary = ' '.join(words[:12])
                    # Add natural ending if needed
                    if not commentary.endswith(('!', '?', 'ред', '...')):
                        commentary += '!'
                
                # Check if it's too similar to recent ones
                if self._is_too_similar(commentary):
                    print("тЪая╕П Commentary too similar to recent ones, using fallback")
                    return self._get_fallback_commentary()
                
                # Store in recent comments
                self.recent_comments.append(commentary)
                self.comment_count += 1
                
                return commentary
            else:
                print(f"тЭМ Ollama API error: {response.status_code}")
                return self._get_fallback_commentary()
                
        except requests.exceptions.Timeout:
            print("тЪая╕П Ollama timeout (>20s) - using fallback")
            return self._get_fallback_commentary()
        except Exception as e:
            print(f"тЭМ Error generating commentary: {e}")
            return self._get_fallback_commentary()
    
    def _is_too_similar(self, new_comment: str) -> bool:
        """Check if new comment is too similar to recent ones"""
        if not self.recent_comments:
            return False
        
        new_words = set(new_comment.lower().split())
        for old_comment in list(self.recent_comments)[-3:]:  # Check last 3
            old_words = set(old_comment.lower().split())
            # Calculate word overlap
            if len(new_words & old_words) > len(new_words) * 0.6:  # >60% overlap
                return True
        return False
    
    def _get_fallback_commentary(self) -> str:
        """Get fallback Hindi commentary with LIVE streaming feel"""
        # LIVE streaming style fallbacks - natural, spontaneous
        fallbacks = [
            "рдЕрд░реЗ... рдпреЗ рджреЗрдЦреЛ рдпрд╛рд░!",
            "рд░реБрдХреЛ рд░реБрдХреЛ... рд╡рд╛рд╣!",
            "рдУрд╣! рдпреЗ рддреЛ... nice!",
            "рд╣рдореНрдо... interesting scene рд╣реИ!",
            "рджреЗрдЦреЛ guys... рдпреЗ рдХреНрдпрд╛ рд╣реИ!",
            "рдЕрднреА... рдЕрднреА рдХреБрдЫ рд╣реЛрдЧрд╛!",
            "рдпреЛ! check рдХрд░реЛ рдпреЗ!",
            "рднрд╛рдИ... seriously?",
            "рдЕрдЪреНрдЫрд╛ рддреЛ... рдУрд╣ wow!",
            "рдПрдХ sec... damn!",
            "рдпрд╛рд░ trust me... epic рд╣реИ!",
            "so... let's see... nice!",
            "рдЕрд░реЗ рдирд╣реАрдВ... wait... рд╣рд╛рдВ!",
            "рдУрд╣реЛ... unexpected рдерд╛!",
            "guys... рджреЗрдЦреЛ рдпреЗ!",
            "рддреЛ рдЕрдм... hmm... cool!",
            "рдЕрдмреЗ... рдХреНрдпрд╛ scene!",
            "рд░реБрдХреЛ... рдпреЗ рддреЛ... pro!",
            "oh man... intense рд╣реИ!",
            "рдЪрд▓реЛ рджреЗрдЦрддреЗ... wow!",
            "рдПрдХ min... amazing!",
            "рдпрд╛рд░... no way!",
            "рджреЗрдЦреЛ... рд╣реЛрдиреЗ рд╡рд╛рд▓рд╛ рдХреБрдЫ!",
            "so excited guys!",
            "рдЕрд░реЗ... tension рд╣реЛ рд░рд╣реА!",
            "рд╣рдореНрдо... scary рд▓рдЧ рд░рд╣рд╛!",
            "go go go... yes!",
            "careful... рдУрд╣!",
            "nice nice... good!",
            "рдпрд╛рд░... feeling good!"
        ]
        # Use recent comments to avoid picking same fallback
        used_recently = list(self.recent_comments)[-3:]
        available = [f for f in fallbacks if f not in used_recently]
        if available:
            return random.choice(available)
        return random.choice(fallbacks)
    
    async def speak_commentary(self, text: str) -> None:
        """Convert text to speech using FREE Edge-TTS with natural voice - Optimized for speed"""
        try:
            # Create unique audio file path
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
            audio_file = self.tmp_dir / f"commentary_{timestamp}.mp3"
            
            # Generate speech with Edge-TTS (very natural, human-like)
            # Added rate adjustment for faster speech
            communicate = edge_tts.Communicate(
                text, 
                self.current_voice,
                rate="+15%"  # Slightly faster for more energetic commentary
            )
            await communicate.save(str(audio_file))
            
            # Verify file was created
            if not audio_file.exists():
                raise FileNotFoundError(f"Audio file not created: {audio_file}")
            
            print(f"тЬЕ Audio generated: {audio_file.name}")
            
            # Play audio (non-blocking for faster loop)
            await self._play_audio(audio_file)
            
            # Cleanup after playback (async to not block)
            asyncio.create_task(self._cleanup_audio(audio_file))
                
        except Exception as e:
            print(f"тЭМ Error with text-to-speech: {e}")
            print(f"ЁЯФК [VOICE]: {text}")
    
    async def _cleanup_audio(self, audio_file: Path) -> None:
        """Async cleanup of audio file"""
        try:
            await asyncio.sleep(1)  # Wait a bit before cleanup
            if audio_file.exists():
                audio_file.unlink()
        except Exception:
            pass  # Ignore cleanup errors
    
    async def _play_audio(self, audio_file: Path) -> None:
        """Play audio file using pygame or system player"""
        try:
            if PYGAME_AVAILABLE:
                # Use pygame for reliable playback
                pygame.mixer.music.load(str(audio_file))
                pygame.mixer.music.play()
                
                # Wait for playback to complete
                while pygame.mixer.music.get_busy():
                    await asyncio.sleep(0.1)
                    
            else:
                # Fallback to system audio player
                if self.os_type == "Windows":
                    os.system(f'start /min "" "{audio_file}"')
                elif self.os_type == "Darwin":  # macOS
                    os.system(f'afplay "{audio_file}"')
                else:  # Linux
                    # Try common Linux players
                    for player in ['mpg123', 'ffplay', 'cvlc']:
                        if subprocess.run(['which', player], capture_output=True).returncode == 0:
                            subprocess.run([player, '-q', str(audio_file)], 
                                         stdout=subprocess.DEVNULL, 
                                         stderr=subprocess.DEVNULL)
                            break
                
                # Wait estimated time for playback
                await asyncio.sleep(3)
                
        except Exception as e:
            print(f"тЪая╕П Audio playback warning: {e}")
    
    async def run(self):
        """Main loop: capture, analyze, comment, speak"""
        print("=" * 70)
        print("ЁЯОо STARTING FREE GAMEPLAY COMMENTARY")
        print("=" * 70)
        
        # Check Ollama status
        if not self._check_ollama_status():
            print("\nтЪая╕П SETUP REQUIRED:")
            print("1. Install Ollama: https://ollama.ai/download")
            print("2. Start Ollama: ollama serve")
            print("3. Pull LLaVA model: ollama pull llava")
            print("\nThen run this script again!")
            return
        
        print("ЁЯУ╣ Capturing your screen and generating AI commentary...")
        print("ЁЯЫС Press Ctrl+C to stop\n")
        
        try:
            while True:
                loop_start = time.time()
                
                print(f"\n{'='*70}")
                print(f"ЁЯОм Comment #{self.comment_count + 1} | {datetime.now().strftime('%H:%M:%S')}")
                print(f"{'='*70}")
                
                # Step 1: Capture screen
                print("ЁЯУ╕ Capturing gameplay...")
                screenshot = self.capture_screen()
                print(f"тЬЕ Screenshot captured ({screenshot.width}x{screenshot.height})")
                
                # Step 2: Generate commentary with Ollama
                print("ЁЯдЦ Ollama analyzing gameplay (local AI)...")
                commentary = await self.generate_commentary_ollama(screenshot)
                print(f"\nЁЯТм COMMENTARY: \"{commentary}\"\n")
                
                # Step 3: Speak commentary
                print("ЁЯОЩя╕П Speaking commentary...")
                await self.speak_commentary(commentary)
                print("тЬЕ Commentary delivered!")
                
                # Calculate time and sleep
                elapsed = time.time() - loop_start
                sleep_time = max(0, self.screenshot_interval - elapsed)
                
                if sleep_time > 0:
                    print(f"тП│ Waiting {sleep_time:.1f}s before next commentary...")
                    await asyncio.sleep(sleep_time)
                
        except KeyboardInterrupt:
            print("\n\n" + "="*70)
            print("ЁЯЫС COMMENTARY STOPPED")
            print("="*70)
            print(f"ЁЯУК Total comments generated: {self.comment_count}")
            print("ЁЯСЛ Thanks for using FREE AI commentary!")
            print("="*70)
        
        except Exception as e:
            print(f"\nтЭМ Unexpected error: {e}")
            import traceback
            traceback.print_exc()

async def main():
    """Entry point for the free gameplay commentator"""
    print("""
    тХФтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХЧ
    тХС                                                               тХС
    тХС       ЁЯОо FREE AI GAMEPLAY COMMENTATOR v3.0 ЁЯОЩя╕П                тХС
    тХС                                                               тХС
    тХС       Powered by Ollama + LLaVA (100% FREE!)                 тХС
    тХС       тАв No API costs, ever                                    тХС
    тХС       тАв Runs completely offline                               тХС
    тХС       тАв Natural voice with pyttsx3                            тХС
    тХС                                                               тХС
    тХЪтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХРтХЭ
    """)
    
    commentator = GameplayCommentatorFree()
    await commentator.run()

if __name__ == "__main__":
    asyncio.run(main())
